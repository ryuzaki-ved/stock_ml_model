{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa01ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Analyze predictions stored by the API/performance tracker\n",
    "conn = sqlite3.connect('predictions.db')\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM predictions ORDER BY predicted_at DESC\", conn)\n",
    "print('Rows in predictions:', len(df))\n",
    "print(df.head())\n",
    "\n",
    "# Basic metrics for last 30 days\n",
    "cutoff = (datetime.now() - timedelta(days=30)).isoformat()\n",
    "recent = pd.read_sql(\"SELECT * FROM predictions WHERE predicted_at > ?\", conn, params=(cutoff,))\n",
    "if len(recent):\n",
    "    acc = (recent['prediction'] == recent['actual_outcome']).mean() if 'actual_outcome' in recent.columns and recent['actual_outcome'].notna().any() else None\n",
    "    print('Recent rows:', len(recent), 'Accuracy:', acc)\n",
    "else:\n",
    "    print('No recent predictions found.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Basic counts and latest timestamps\n",
    "print('Total rows:', len(df))\n",
    "if len(df):\n",
    "    print('First ts:', df['predicted_at'].min())\n",
    "    print('Last ts:', df['predicted_at'].max())\n",
    "    print('Unique symbols:', df['symbol'].nunique())\n",
    "    print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Recent accuracy and win rate\n",
    "if len(df):\n",
    "    mask = df['actual_outcome'].notna()\n",
    "    eval_df = df[mask].copy()\n",
    "    if len(eval_df):\n",
    "        acc = (eval_df['prediction'] == eval_df['actual_outcome']).mean()\n",
    "        win_rate = (eval_df['actual_return'] > 0).mean()\n",
    "        print('Overall accuracy:', round(float(acc), 4))\n",
    "        print('Overall win rate:', round(float(win_rate), 4))\n",
    "    else:\n",
    "        print('No rows with actual outcomes yet.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb21c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Sharpe-like metric on realized returns\n",
    "import numpy as np\n",
    "\n",
    "if len(df) and 'actual_return' in df.columns and df['actual_return'].notna().any():\n",
    "    r = df['actual_return'].dropna()\n",
    "    sharpe = r.mean() / (r.std() + 1e-9) * np.sqrt(252)\n",
    "    print('Sharpe (approx):', round(float(sharpe), 3))\n",
    "else:\n",
    "    print('No realized returns available for Sharpe calculation.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Per-symbol performance summary\n",
    "if len(df):\n",
    "    if 'actual_return' in df.columns:\n",
    "        by_symbol = df.groupby('symbol')['actual_return'].agg(['mean','std','count']).reset_index()\n",
    "        by_symbol = by_symbol.sort_values('mean', ascending=False)\n",
    "        print(by_symbol.head(10))\n",
    "    else:\n",
    "        print('actual_return column missing. Run performance tracker updates.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ce1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Confusion matrix from realized outcomes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mask = df['actual_outcome'].notna()\n",
    "if mask.any():\n",
    "    cm = confusion_matrix(df.loc[mask,'actual_outcome'], df.loc[mask,'prediction'], labels=[-1,0,1])\n",
    "    print('Confusion matrix:')\n",
    "    print(cm)\n",
    "else:\n",
    "    print('No actual outcomes yet to compute confusion matrix.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d030ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Daily prediction volume and signal counts\n",
    "if len(df):\n",
    "    counts = df.groupby(['predicted_at']).size().rename('count').reset_index()\n",
    "    print(counts.head(10))\n",
    "    sig_counts = df.groupby(['predicted_at','prediction']).size().unstack(fill_value=0)\n",
    "    print(sig_counts.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f1a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Confidence calibration (if confidence logged)\n",
    "if 'confidence' in df.columns:\n",
    "    conf_desc = df['confidence'].describe()\n",
    "    print('Confidence stats:', conf_desc.to_dict())\n",
    "    by_pred = df.groupby('prediction')['confidence'].mean().round(3)\n",
    "    print('Avg confidence by predicted class:', by_pred.to_dict())\n",
    "else:\n",
    "    print('No confidence column found.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe477ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Latency/throughput placeholders\n",
    "# If API logged latency, you could analyze here. For now, placeholders:\n",
    "api_metrics = {\n",
    "    'p50_ms': None,\n",
    "    'p90_ms': None,\n",
    "    'requests_per_min': None,\n",
    "}\n",
    "print('API metrics:', api_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Export a daily KPI table\n",
    "if len(df) and 'actual_return' in df.columns:\n",
    "    daily_kpi = df.groupby(df['predicted_at'].str[:10]).agg(\n",
    "        n=('symbol','count'),\n",
    "        win_rate=('actual_return', lambda s: (s > 0).mean() if len(s) else None),\n",
    "        avg_return=('actual_return','mean')\n",
    "    ).reset_index().rename(columns={'predicted_at':'date'})\n",
    "    print(daily_kpi.head(10))\n",
    "else:\n",
    "    print('Not enough data to compute daily KPI.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498df12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Top/bottom symbols by realized return (recent)\n",
    "if len(df) and 'actual_return' in df.columns:\n",
    "    recent_mask = df['predicted_at'] >= cutoff\n",
    "    recent_df = df.loc[recent_mask].copy()\n",
    "    agg = recent_df.groupby('symbol')['actual_return'].mean().reset_index()\n",
    "    print('Top 10 symbols (avg return):')\n",
    "    print(agg.sort_values('actual_return', ascending=False).head(10))\n",
    "    print('Bottom 10 symbols (avg return):')\n",
    "    print(agg.sort_values('actual_return', ascending=True).head(10))\n",
    "else:\n",
    "    print('No recent realized returns to rank symbols.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b793a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Export report CSVs\n",
    "out_dir = 'data/predictions'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "df.to_csv(os.path.join(out_dir, 'predictions_dump.csv'), index=False)\n",
    "print('Wrote', os.path.join(out_dir, 'predictions_dump.csv'))\n",
    "\n",
    "# Save daily KPI if computed above\n",
    "try:\n",
    "    daily_kpi.to_csv(os.path.join(out_dir, 'daily_kpi.csv'), index=False)\n",
    "    print('Wrote daily_kpi.csv')\n",
    "except Exception as e:\n",
    "    print('daily_kpi not available:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d4a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Summary and next steps\n",
    "print('Analysis complete.')\n",
    "print('Suggested next steps:')\n",
    "print('- Improve label quality and update_actual_outcomes scheduling.')\n",
    "print('- Calibrate thresholds and explore cost-sensitive metrics.')\n",
    "print('- Add drift and data quality dashboards if needed.')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
